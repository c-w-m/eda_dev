{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Multiple Excel Files with Pandas\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common tasks for pandas and python is to automate the process to aggregate data from multiple spreadsheets and files.\n",
    "\n",
    "This article will walk through the basic flow required to parse multiple excel files, combine some data, clean it up and analyze it.\n",
    "\n",
    "Please refer to [Combining Data From Multiple Excel Files](https://pbpython.com/excel-file-combine.html) for the full post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "WIN = 'Windows'\n",
    "NIX = 'Linux'\n",
    "OSX = 'OSX'\n",
    "platforms = {\n",
    "    'linux' : NIX,\n",
    "    'linux1' : NIX,\n",
    "    'linux2' : NIX,\n",
    "    'darwin' : OSX,\n",
    "    'win32' : WIN\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the files in our input directory, using the convenient shell commands in ipython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018_Sales_Total_Tabs.xlsx\t\t  sales-estimate.xlsx\n",
      "2018_Sales_Total_v2.xlsx\t\t  sales-feb-2014 (1).xlsx\n",
      "2018_Sales_Total.xlsx\t\t\t  sales-feb-2014.xlsx\n",
      "All-Web-Site-Data-Audience-Overview.xlsx  salesfunnel.xlsx\n",
      "Aussie_Wines_Plotting.csv\t\t  sales-jan-2014(1).xlsx\n",
      "cereal_data.csv\t\t\t\t  sales-jan-2014.xlsx\n",
      "customer-status (1).xlsx\t\t  sales-mar-2014 (1).xlsx\n",
      "customer-status.xlsx\t\t\t  sales-mar-2014.xlsx\n",
      "hospital_account_dupes.csv\t\t  sales_transactions.xlsx\n",
      "hospital_account_info.csv\t\t  sample-address-1.xlsx\n",
      "hospital_reimbursement.csv\t\t  sample-address-2.xlsx\n",
      "March-2017-forecast-article.xlsx\t  sample-sales-reps.xlsx\n",
      "mn-budget-detail-2014.csv\t\t  sample-sales-tax.csv\n",
      "MN_Traffic_Fatalities.csv\t\t  sample-salesv2.csv\n",
      "Online_Retail.xlsx\t\t\t  sample-salesv3.xlsx\n",
      "sales_cleanup.xlsx\t\t\t  school_transform.csv\n",
      "sales_data_types.csv\t\t\t  shipping_tables.xlsx\n",
      "sales-estimate.csv\t\t\t  Traffic_20170306-20170519.xlsx\n"
     ]
    }
   ],
   "source": [
    "if platforms[sys.platform] == WIN:\n",
    "    !dir \"../data\"\n",
    "elif platforms[sys.platform] == NIX  or os_platform == OSX:\n",
    "    !ls ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of files, but we only want to look at the `sales-*-2014.xlsx` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sales-feb-2014.xlsx  ../data/sales-mar-2014.xlsx\n",
      "../data/sales-jan-2014.xlsx\n"
     ]
    }
   ],
   "source": [
    "if platforms[sys.platform] == WIN:\n",
    "    !dir \"../data/sales-*-2014.xlsx\"\n",
    "elif platforms[sys.platform] == NIX  or os_platform == OSX:\n",
    "    !ls ../data/sales-*-2014.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the python `glob` module to easily list out the files we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/sales-feb-2014.xlsx',\n",
       " '../data/sales-mar-2014.xlsx',\n",
       " '../data/sales-jan-2014.xlsx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob(\"../data/sales-*-2014.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us what we need, let's import each of our files and combine them into one file. Panda's `concat` and `append` can do this for us. I'm going to use `append` in this example.\n",
    "\n",
    "The code snippet below will initialize a blank DataFrame then append all of the individual files into the `all_data` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "for f in glob.glob(\"../data/sales-*-2014.xlsx\"):\n",
    "    df = pd.read_excel(f)\n",
    "    all_data = all_data.append(df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the data in our all_data DataFrame. You can use describe to look at it and make sure you data looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account number</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit price</th>\n",
       "      <th>ext price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>384.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>478125.989583</td>\n",
       "      <td>24.372396</td>\n",
       "      <td>56.651406</td>\n",
       "      <td>1394.517344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>220902.947401</td>\n",
       "      <td>14.373219</td>\n",
       "      <td>27.075883</td>\n",
       "      <td>1117.809743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>141962.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>10.210000</td>\n",
       "      <td>-97.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>257198.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>32.612500</td>\n",
       "      <td>482.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>424914.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>58.160000</td>\n",
       "      <td>1098.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>714466.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>80.965000</td>\n",
       "      <td>2132.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>786968.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>99.730000</td>\n",
       "      <td>4590.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account number    quantity  unit price    ext price\n",
       "count      384.000000  384.000000  384.000000   384.000000\n",
       "mean    478125.989583   24.372396   56.651406  1394.517344\n",
       "std     220902.947401   14.373219   27.075883  1117.809743\n",
       "min     141962.000000   -1.000000   10.210000   -97.160000\n",
       "25%     257198.000000   12.000000   32.612500   482.745000\n",
       "50%     424914.000000   23.500000   58.160000  1098.710000\n",
       "75%     714466.000000   37.000000   80.965000  2132.260000\n",
       "max     786968.000000   49.000000   99.730000  4590.810000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alot of this data may not make much sense for this data set but I'm most interested in the count row to make sure the number of data elements makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account number</th>\n",
       "      <th>name</th>\n",
       "      <th>sku</th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit price</th>\n",
       "      <th>ext price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>383080</td>\n",
       "      <td>Will LLC</td>\n",
       "      <td>B1-20000</td>\n",
       "      <td>7</td>\n",
       "      <td>33.69</td>\n",
       "      <td>235.83</td>\n",
       "      <td>2014-02-01 09:04:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412290</td>\n",
       "      <td>Jerde-Hilpert</td>\n",
       "      <td>S1-27722</td>\n",
       "      <td>11</td>\n",
       "      <td>21.12</td>\n",
       "      <td>232.32</td>\n",
       "      <td>2014-02-01 11:51:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412290</td>\n",
       "      <td>Jerde-Hilpert</td>\n",
       "      <td>B1-86481</td>\n",
       "      <td>3</td>\n",
       "      <td>35.99</td>\n",
       "      <td>107.97</td>\n",
       "      <td>2014-02-01 17:24:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>412290</td>\n",
       "      <td>Jerde-Hilpert</td>\n",
       "      <td>B1-20000</td>\n",
       "      <td>23</td>\n",
       "      <td>78.90</td>\n",
       "      <td>1814.70</td>\n",
       "      <td>2014-02-01 19:56:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>672390</td>\n",
       "      <td>Kuhn-Gusikowski</td>\n",
       "      <td>S1-06532</td>\n",
       "      <td>48</td>\n",
       "      <td>55.82</td>\n",
       "      <td>2679.36</td>\n",
       "      <td>2014-02-02 03:45:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account number             name       sku  quantity  unit price  ext price  \\\n",
       "0          383080         Will LLC  B1-20000         7       33.69     235.83   \n",
       "1          412290    Jerde-Hilpert  S1-27722        11       21.12     232.32   \n",
       "2          412290    Jerde-Hilpert  B1-86481         3       35.99     107.97   \n",
       "3          412290    Jerde-Hilpert  B1-20000        23       78.90    1814.70   \n",
       "4          672390  Kuhn-Gusikowski  S1-06532        48       55.82    2679.36   \n",
       "\n",
       "                  date  \n",
       "0  2014-02-01 09:04:59  \n",
       "1  2014-02-01 11:51:46  \n",
       "2  2014-02-01 17:24:32  \n",
       "3  2014-02-01 19:56:48  \n",
       "4  2014-02-02 03:45:20  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not critical in this example but the best practice is to convert the date column to a date time object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['date'] = pd.to_datetime(all_data['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the data into one DataFrame, we can do any manipulations the DataFrame supports. In this case, the next thing we want to do is read in another file that contains the customer status by account. You can think of this as a company's customer segmentation strategy or some other mechanism for identifying their customers.\n",
    "\n",
    "First, we read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pd.read_excel(\"../data/customer-status.xlsx\")\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to merge this data with our concatenated data set of sales. We use panda's merge function and tell it to do a left join which is similar to Excel's vlookup function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st = pd.merge(all_data, status, how='left')\n",
    "all_data_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good but let's look at a specific account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st[all_data_st[\"account number\"]==737550].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This account number was not in our status file, so we have a bunch of NaN's. We can decide how we want to handle this situation. For this specific case, let's label all missing accounts as bronze. Use the fillna function to easily accomplish this on the status column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st['status'].fillna('bronze',inplace=True)\n",
    "all_data_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data just to make sure we're all good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st[all_data_st[\"account number\"]==737550].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all of the data along with the status column filled in. We can do our normal data manipulations using the full suite of pandas capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the relatively new functions in pandas is support for categorical data. From the pandas, documentation -\n",
    "\n",
    "\"Categoricals are a pandas data type, which correspond to categorical variables in statistics: a variable, which can take on only a limited, and usually fixed, number of possible values (categories; levels in R). Examples are gender, social class, blood types, country affiliations, observation time or ratings via Likert scales.\"\n",
    "\n",
    "For our purposes, the status field is a good candidate for a category type.\n",
    "\n",
    "You must make sure you have a recent version of pandas installed for this example to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we typecast it to a category using astype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st[\"status\"] = all_data_st[\"status\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't immediately appear to change anything yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buy you can see that it is a new data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories get more interesting when you assign order to the categories. Right now, if we call sort on the column, it will sort alphabetically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st.sort_values(by=[\"status\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use set_categories to tell it the order we want to use for this category object. In this case, we use the Olympic medal ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " all_data_st[\"status\"].cat.set_categories([ \"gold\",\"silver\",\"bronze\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can sort it so that gold shows on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st.sort_values(by=[\"status\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st[\"status\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, if you want to take a quick look at how your top tier customers are performaing compared to the bottom. Use groupby to give us the average of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st.groupby([\"status\"])[\"quantity\",\"unit price\",\"ext price\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can run multiple aggregation functions on the data to get really useful information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st.groupby([\"status\"])[\"quantity\",\"unit price\",\"ext price\"].agg([np.sum,np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what does this tell you? Well, the data is completely random but my first observation is that we sell more units to our bronze customers than gold. Even when you look at the total dollar value associated with bronze vs. gold, it looks backwards.\n",
    "\n",
    "Maybe we should look at how many bronze customers we have and see what is going on.\n",
    "\n",
    "What I plan to do is filter out the unique accounts and see how many gold, silver and bronze customers there are.\n",
    "\n",
    "I'm purposely stringing a lot of commands together which is not necessarily best practice but does show how powerful pandas can be. Feel free to review my previous articles and play with this command yourself to understand what all these commands mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_st.drop_duplicates(subset=[\"account number\",\"name\"]).iloc[:,[0,1,7]].groupby([\"status\"])[\"name\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. This makes a little more sense. We see that we have 9 bronze customers and only 4 customers. That is probably why the volumes are so skewed towards our bronze customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*EOF*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_dev39",
   "language": "python",
   "name": "eda_dev39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
