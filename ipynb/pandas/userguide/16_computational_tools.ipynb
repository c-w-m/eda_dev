{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d3efc-e51e-4e45-94b4-ed1e98f6e34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebebc1-b99f-4f2b-9088-098b7fe8ed4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09815b-f7c8-458e-9d54-ded1427183f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e886d31-21e3-4780-b386-e8dae26a29d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfba15c-0ab9-4459-9624-cb320c5c14ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f8fc2-c164-49a8-81c1-09e63b742b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708da0ad-7d34-4e1e-8f05-2e17a0f42c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2545aed8-6682-46cf-ab6f-a1389aa582a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08f96e-a562-462d-bc3d-9732bc2079f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9e58e27-f3fa-4afe-8ded-f701737db6b4",
   "metadata": {},
   "source": [
    "# Computational tools\n",
    "Statistical functions\n",
    "Percent change\n",
    "Series and DataFrame have a method pct_change() to compute the percent change over a given number of periods (using fill_method to fill NA/null values before computing the percent change).\n",
    "\n",
    "In [1]: ser = pd.Series(np.random.randn(8))\n",
    "\n",
    "In [2]: ser.pct_change()\n",
    "Out[2]: \n",
    "0         NaN\n",
    "1   -1.602976\n",
    "2    4.334938\n",
    "3   -0.247456\n",
    "4   -2.067345\n",
    "5   -1.142903\n",
    "6   -1.688214\n",
    "7   -9.759729\n",
    "dtype: float64\n",
    "In [3]: df = pd.DataFrame(np.random.randn(10, 4))\n",
    "\n",
    "In [4]: df.pct_change(periods=3)\n",
    "Out[4]: \n",
    "          0         1         2         3\n",
    "0       NaN       NaN       NaN       NaN\n",
    "1       NaN       NaN       NaN       NaN\n",
    "2       NaN       NaN       NaN       NaN\n",
    "3 -0.218320 -1.054001  1.987147 -0.510183\n",
    "4 -0.439121 -1.816454  0.649715 -4.822809\n",
    "5 -0.127833 -3.042065 -5.866604 -1.776977\n",
    "6 -2.596833 -1.959538 -2.111697 -3.798900\n",
    "7 -0.117826 -2.169058  0.036094 -0.067696\n",
    "8  2.492606 -1.357320 -1.205802 -1.558697\n",
    "9 -1.012977  2.324558 -1.003744 -0.371806\n",
    "Covariance\n",
    "Series.cov() can be used to compute covariance between series (excluding missing values).\n",
    "\n",
    "In [5]: s1 = pd.Series(np.random.randn(1000))\n",
    "\n",
    "In [6]: s2 = pd.Series(np.random.randn(1000))\n",
    "\n",
    "In [7]: s1.cov(s2)\n",
    "Out[7]: 0.0006801088174310875\n",
    "Analogously, DataFrame.cov() to compute pairwise covariances among the series in the DataFrame, also excluding NA/null values.\n",
    "\n",
    "Note\n",
    "\n",
    "Assuming the missing data are missing at random this results in an estimate for the covariance matrix which is unbiased. However, for many applications this estimate may not be acceptable because the estimated covariance matrix is not guaranteed to be positive semi-definite. This could lead to estimated correlations having absolute values which are greater than one, and/or a non-invertible covariance matrix. See Estimation of covariance matrices for more details.\n",
    "\n",
    "In [8]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "\n",
    "In [9]: frame.cov()\n",
    "Out[9]: \n",
    "          a         b         c         d         e\n",
    "a  1.000882 -0.003177 -0.002698 -0.006889  0.031912\n",
    "b -0.003177  1.024721  0.000191  0.009212  0.000857\n",
    "c -0.002698  0.000191  0.950735 -0.031743 -0.005087\n",
    "d -0.006889  0.009212 -0.031743  1.002983 -0.047952\n",
    "e  0.031912  0.000857 -0.005087 -0.047952  1.042487\n",
    "DataFrame.cov also supports an optional min_periods keyword that specifies the required minimum number of observations for each column pair in order to have a valid result.\n",
    "\n",
    "In [10]: frame = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "In [11]: frame.loc[frame.index[:5], \"a\"] = np.nan\n",
    "\n",
    "In [12]: frame.loc[frame.index[5:10], \"b\"] = np.nan\n",
    "\n",
    "In [13]: frame.cov()\n",
    "Out[13]: \n",
    "          a         b         c\n",
    "a  1.123670 -0.412851  0.018169\n",
    "b -0.412851  1.154141  0.305260\n",
    "c  0.018169  0.305260  1.301149\n",
    "\n",
    "In [14]: frame.cov(min_periods=12)\n",
    "Out[14]: \n",
    "          a         b         c\n",
    "a  1.123670       NaN  0.018169\n",
    "b       NaN  1.154141  0.305260\n",
    "c  0.018169  0.305260  1.301149\n",
    "Correlation\n",
    "Correlation may be computed using the corr() method. Using the method parameter, several methods for computing correlations are provided:\n",
    "\n",
    "Method name\n",
    "\n",
    "Description\n",
    "\n",
    "pearson (default)\n",
    "\n",
    "Standard correlation coefficient\n",
    "\n",
    "kendall\n",
    "\n",
    "Kendall Tau correlation coefficient\n",
    "\n",
    "spearman\n",
    "\n",
    "Spearman rank correlation coefficient\n",
    "\n",
    "All of these are currently computed using pairwise complete observations. Wikipedia has articles covering the above correlation coefficients:\n",
    "\n",
    "Pearson correlation coefficient\n",
    "\n",
    "Kendall rank correlation coefficient\n",
    "\n",
    "Spearmanâ€™s rank correlation coefficient\n",
    "\n",
    "Note\n",
    "\n",
    "Please see the caveats associated with this method of calculating correlation matrices in the covariance section.\n",
    "\n",
    "In [15]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "\n",
    "In [16]: frame.iloc[::2] = np.nan\n",
    "\n",
    "# Series with Series\n",
    "In [17]: frame[\"a\"].corr(frame[\"b\"])\n",
    "Out[17]: 0.013479040400098775\n",
    "\n",
    "In [18]: frame[\"a\"].corr(frame[\"b\"], method=\"spearman\")\n",
    "Out[18]: -0.007289885159540637\n",
    "\n",
    "# Pairwise correlation of DataFrame columns\n",
    "In [19]: frame.corr()\n",
    "Out[19]: \n",
    "          a         b         c         d         e\n",
    "a  1.000000  0.013479 -0.049269 -0.042239 -0.028525\n",
    "b  0.013479  1.000000 -0.020433 -0.011139  0.005654\n",
    "c -0.049269 -0.020433  1.000000  0.018587 -0.054269\n",
    "d -0.042239 -0.011139  0.018587  1.000000 -0.017060\n",
    "e -0.028525  0.005654 -0.054269 -0.017060  1.000000\n",
    "Note that non-numeric columns will be automatically excluded from the correlation calculation.\n",
    "\n",
    "Like cov, corr also supports the optional min_periods keyword:\n",
    "\n",
    "In [20]: frame = pd.DataFrame(np.random.randn(20, 3), columns=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "In [21]: frame.loc[frame.index[:5], \"a\"] = np.nan\n",
    "\n",
    "In [22]: frame.loc[frame.index[5:10], \"b\"] = np.nan\n",
    "\n",
    "In [23]: frame.corr()\n",
    "Out[23]: \n",
    "          a         b         c\n",
    "a  1.000000 -0.121111  0.069544\n",
    "b -0.121111  1.000000  0.051742\n",
    "c  0.069544  0.051742  1.000000\n",
    "\n",
    "In [24]: frame.corr(min_periods=12)\n",
    "Out[24]: \n",
    "          a         b         c\n",
    "a  1.000000       NaN  0.069544\n",
    "b       NaN  1.000000  0.051742\n",
    "c  0.069544  0.051742  1.000000\n",
    "New in version 0.24.0.\n",
    "\n",
    "The method argument can also be a callable for a generic correlation calculation. In this case, it should be a single function that produces a single value from two ndarray inputs. Suppose we wanted to compute the correlation based on histogram intersection:\n",
    "\n",
    "# histogram intersection\n",
    "In [25]: def histogram_intersection(a, b):\n",
    "   ....:     return np.minimum(np.true_divide(a, a.sum()), np.true_divide(b, b.sum())).sum()\n",
    "   ....: \n",
    "\n",
    "In [26]: frame.corr(method=histogram_intersection)\n",
    "Out[26]: \n",
    "          a          b          c\n",
    "a  1.000000  -6.404882  -2.058431\n",
    "b -6.404882   1.000000 -19.255743\n",
    "c -2.058431 -19.255743   1.000000\n",
    "A related method corrwith() is implemented on DataFrame to compute the correlation between like-labeled Series contained in different DataFrame objects.\n",
    "\n",
    "In [27]: index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "\n",
    "In [28]: columns = [\"one\", \"two\", \"three\", \"four\"]\n",
    "\n",
    "In [29]: df1 = pd.DataFrame(np.random.randn(5, 4), index=index, columns=columns)\n",
    "\n",
    "In [30]: df2 = pd.DataFrame(np.random.randn(4, 4), index=index[:4], columns=columns)\n",
    "\n",
    "In [31]: df1.corrwith(df2)\n",
    "Out[31]: \n",
    "one     -0.125501\n",
    "two     -0.493244\n",
    "three    0.344056\n",
    "four     0.004183\n",
    "dtype: float64\n",
    "\n",
    "In [32]: df2.corrwith(df1, axis=1)\n",
    "Out[32]: \n",
    "a   -0.675817\n",
    "b    0.458296\n",
    "c    0.190809\n",
    "d   -0.186275\n",
    "e         NaN\n",
    "dtype: float64\n",
    "Data ranking\n",
    "The rank() method produces a data ranking with ties being assigned the mean of the ranks (by default) for the group:\n",
    "\n",
    "In [33]: s = pd.Series(np.random.randn(5), index=list(\"abcde\"))\n",
    "\n",
    "In [34]: s[\"d\"] = s[\"b\"]  # so there's a tie\n",
    "\n",
    "In [35]: s.rank()\n",
    "Out[35]: \n",
    "a    5.0\n",
    "b    2.5\n",
    "c    1.0\n",
    "d    2.5\n",
    "e    4.0\n",
    "dtype: float64\n",
    "rank() is also a DataFrame method and can rank either the rows (axis=0) or the columns (axis=1). NaN values are excluded from the ranking.\n",
    "\n",
    "In [36]: df = pd.DataFrame(np.random.randn(10, 6))\n",
    "\n",
    "In [37]: df[4] = df[2][:5]  # some ties\n",
    "\n",
    "In [38]: df\n",
    "Out[38]: \n",
    "          0         1         2         3         4         5\n",
    "0 -0.904948 -1.163537 -1.457187  0.135463 -1.457187  0.294650\n",
    "1 -0.976288 -0.244652 -0.748406 -0.999601 -0.748406 -0.800809\n",
    "2  0.401965  1.460840  1.256057  1.308127  1.256057  0.876004\n",
    "3  0.205954  0.369552 -0.669304  0.038378 -0.669304  1.140296\n",
    "4 -0.477586 -0.730705 -1.129149 -0.601463 -1.129149 -0.211196\n",
    "5 -1.092970 -0.689246  0.908114  0.204848       NaN  0.463347\n",
    "6  0.376892  0.959292  0.095572 -0.593740       NaN -0.069180\n",
    "7 -1.002601  1.957794 -0.120708  0.094214       NaN -1.467422\n",
    "8 -0.547231  0.664402 -0.519424 -0.073254       NaN -1.263544\n",
    "9 -0.250277 -0.237428 -1.056443  0.419477       NaN  1.375064\n",
    "\n",
    "In [39]: df.rank(1)\n",
    "Out[39]: \n",
    "     0    1    2    3    4    5\n",
    "0  4.0  3.0  1.5  5.0  1.5  6.0\n",
    "1  2.0  6.0  4.5  1.0  4.5  3.0\n",
    "2  1.0  6.0  3.5  5.0  3.5  2.0\n",
    "3  4.0  5.0  1.5  3.0  1.5  6.0\n",
    "4  5.0  3.0  1.5  4.0  1.5  6.0\n",
    "5  1.0  2.0  5.0  3.0  NaN  4.0\n",
    "6  4.0  5.0  3.0  1.0  NaN  2.0\n",
    "7  2.0  5.0  3.0  4.0  NaN  1.0\n",
    "8  2.0  5.0  3.0  4.0  NaN  1.0\n",
    "9  2.0  3.0  1.0  4.0  NaN  5.0\n",
    "rank optionally takes a parameter ascending which by default is true; when false, data is reverse-ranked, with larger values assigned a smaller rank.\n",
    "\n",
    "rank supports different tie-breaking methods, specified with the method parameter:\n",
    "\n",
    "average : average rank of tied group\n",
    "\n",
    "min : lowest rank in the group\n",
    "\n",
    "max : highest rank in the group\n",
    "\n",
    "first : ranks assigned in the order they appear in the array\n",
    "\n",
    "Windowing functions\n",
    "See the window operations user guide for an overview of windowing functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_dev39",
   "language": "python",
   "name": "eda_dev39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
